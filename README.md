# ğŸ§  Multimodal Digit Recognition

A multimodal machine learning project that classifies handwritten digits using both **image** and **spoken audio** inputs. Combines visual and acoustic features with a custom **feature fusion strategy** to improve classification accuracy.

---

## ğŸ”§ Tech Stack

- **Languages:** Python  
- **Libraries:** PyTorch, NumPy, Matplotlib, scikit-learn  
- **Techniques:** CNN (image encoder), Fully Connected NN (audio encoder), feature fusion, t-SNE visualization

---

## ğŸ“Š Results

- Achieved **0.992 macro F1 score** on the **Multimodal MNIST dataset**
- Outperformed benchmark models from previous published research
- Conducted ablation studies to analyze contribution of each modality

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ data/                 # Image & audio inputs
â”œâ”€â”€ models/               # CNN & FC model definitions
â”œâ”€â”€ train.py              # Training script
â”œâ”€â”€ evaluate.py           # Metrics and visualization
â”œâ”€â”€ utils/                # Feature extraction, fusion
â””â”€â”€ README.md             # You're here!
```

---

## ğŸ§ª How to Run

1. Clone this repo  
2. Install dependencies:  
   `pip install -r requirements.txt`  
3. Run training:  
   `python train.py`  
4. Evaluate:  
   `python evaluate.py`

---
